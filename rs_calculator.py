# -*- coding: utf-8 -*-
"""rs_calculator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11vlqOMado1_DXASt6onK0l5thD1pJTY6
"""

import pandas as pd
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================
BASE_PATH = "."
MASTER_CSV_FILE = os.path.join(BASE_PATH, "master_nifty500_cleaned.csv")
CURRENT_TICKER_FILE = os.path.join(BASE_PATH, "ind_nifty500list.csv")
RS_MASTER_CSV = os.path.join(BASE_PATH, "rs_master.csv")
RS_MASTER_EXCEL = os.path.join(BASE_PATH, "rs_master.xlsx")

# ==========================================
# 2. RS CALCULATION FUNCTION
# ==========================================
def calculate_rs_for_date(target_date, close_px, full_data, ind_map):
    # Calculate historical target dates
    date_1d = target_date - pd.DateOffset(days=1)
    date_1w = target_date - pd.DateOffset(weeks=1)
    date_1m = target_date - pd.DateOffset(months=1)
    date_3m = target_date - pd.DateOffset(months=3)
    date_6m = target_date - pd.DateOffset(months=6)
    date_9m = target_date - pd.DateOffset(months=9)
    date_12m = target_date - pd.DateOffset(months=12)

    try:
        past_data = close_px.loc[:target_date]
        if past_data.empty: return None

        actual_target_date = past_data.index[-1]

        p_now = past_data.iloc[-1]
        p_1d = close_px.loc[:date_1d].iloc[-1]
        p_1w = close_px.loc[:date_1w].iloc[-1]
        p_1m = close_px.loc[:date_1m].iloc[-1]
        p_3m = close_px.loc[:date_3m].iloc[-1]
        p_6m = close_px.loc[:date_6m].iloc[-1]
        p_9m = close_px.loc[:date_9m].iloc[-1]
        p_12m = close_px.loc[:date_12m].iloc[-1]
    except IndexError:
        # Not enough historical data to look back 12 months for this date
        return None

    # Calculate Returns
    returns = pd.DataFrame({
        '1 Day Return': (p_now - p_1d) / p_1d,
        '1 Week Return': (p_now - p_1w) / p_1w,
        '1 Month Return': (p_now - p_1m) / p_1m,
        '3 Month Return': (p_now - p_3m) / p_3m,
        '6 Month Return': (p_now - p_6m) / p_6m,
        '9 Month Return': (p_now - p_9m) / p_9m,
        '12 Month Return': (p_now - p_12m) / p_12m
    })

    returns = returns.dropna()
    if returns.empty: return None

    # Calculate Weighted Avg & RS Score
    returns['Weighted Avg'] = (0.4 * returns['3 Month Return'] +
                               0.2 * returns['6 Month Return'] +
                               0.2 * returns['9 Month Return'] +
                               0.2 * returns['12 Month Return'])

    return_cols = [
        '1 Day Return', '1 Week Return', '1 Month Return',
        '3 Month Return', '6 Month Return', '9 Month Return', '12 Month Return', 'Weighted Avg'
    ]
    for col in return_cols:
        returns[col] = round(returns[col] * 100)

    returns['RS Score'] = returns['Weighted Avg'].rank(pct=True) * 100
    returns['RS Score'] = returns['RS Score'].round(0).clip(lower=1, upper=99).astype(int)

    # Add Price/Volume data
    current_day_data = full_data[full_data['DATE'] == actual_target_date].set_index('TICKER')
    ohlcv_columns = current_day_data[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'TURNOVER']]
    final_table = returns.join(ohlcv_columns, how='left')

    column_order = [
        'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'TURNOVER', '1 Day Return', '1 Week Return', '1 Month Return',
        '3 Month Return', '6 Month Return', '9 Month Return', '12 Month Return',
        'Weighted Avg', 'RS Score'
    ]
    final_table = final_table[column_order]

    # Map Industries
    final_table['INDUSTRY'] = final_table.index.map(lambda x: ind_map.get(x, 'Unknown'))

    # Sort and reorder columns
    final_table = final_table.sort_values(by='RS Score', ascending=False)
    cols = ['INDUSTRY'] + [c for c in final_table.columns if c != 'INDUSTRY']
    final_table = final_table[cols]

    # Reset index to make TICKER a column, and insert DATE
    final_table = final_table.reset_index(names='TICKER')
    final_table.insert(0, 'DATE', actual_target_date.strftime('%d-%m-%Y'))

    return final_table

# ==========================================
# 3. MAIN EXECUTION
# ==========================================
if __name__ == "__main__":
    print("--- STARTING RS CALCULATION ---")

    # 1. Load Bhavcopy Master Data
    if not os.path.exists(MASTER_CSV_FILE):
        print(f"Error: {MASTER_CSV_FILE} not found. Please run fetcher.py first.")
        exit()

    df = pd.read_csv(MASTER_CSV_FILE)
    df['DATE'] = pd.to_datetime(df['DATE'], format='%d-%m-%Y')

    # 2. Load Industry Data
    ind_df = pd.read_csv(CURRENT_TICKER_FILE)
    ind_df.columns = ind_df.columns.str.strip()
    industry_mapping = dict(zip(ind_df['Symbol'].str.strip(), ind_df['Industry'].str.strip()))

    # 3. Check for existing RS Master File to determine start date
    if os.path.exists(RS_MASTER_CSV):
        rs_master_df = pd.read_csv(RS_MASTER_CSV)
        rs_master_df['DATE'] = pd.to_datetime(rs_master_df['DATE'], format='%d-%m-%Y')
        last_processed_date = rs_master_df['DATE'].max()
        print(f"Existing RS Master found. Last calculated date: {last_processed_date.strftime('%d-%m-%Y')}")
    else:
        rs_master_df = pd.DataFrame()
        last_processed_date = pd.to_datetime('2000-01-01') # Force it to run all available dates
        print("No existing RS Master found. Creating a new one...")

    # Pivot the close prices ONCE for extreme speed during the loop
    close_px = df.pivot(index='DATE', columns='TICKER', values='CLOSE').sort_index()

    # Identify unique dates in the dataset that need to be processed
    all_dates = df['DATE'].sort_values().unique()
    dates_to_process = [pd.to_datetime(d) for d in all_dates if pd.to_datetime(d) > last_processed_date]

    if not dates_to_process:
        print("RS Data is already up to date!")
    else:
        new_rs_tables = []
        for target in dates_to_process:
            print(f"Calculating RS for {target.strftime('%d-%m-%Y')}...", end=" ")
            daily_rs = calculate_rs_for_date(target, close_px, df, industry_mapping)

            if daily_rs is not None:
                new_rs_tables.append(daily_rs)
                print(f"‚úÖ Success!")
            else:
                print(f"‚è≠Ô∏è Skipped (Not enough historical data)")

        # Save results
        if new_rs_tables:
            new_data_df = pd.concat(new_rs_tables, ignore_index=True)

            # Format dates back to string for consistency before saving
            new_data_df['DATE'] = pd.to_datetime(new_data_df['DATE'], format='%d-%m-%Y')

            full_rs_df = pd.concat([rs_master_df, new_data_df], ignore_index=True)
            full_rs_df = full_rs_df.sort_values(by=['DATE', 'RS Score'], ascending=[True, False])

            full_rs_df['DATE'] = full_rs_df['DATE'].dt.strftime('%d-%m-%Y')

            full_rs_df.to_csv(RS_MASTER_CSV, index=False)
            full_rs_df.to_excel(RS_MASTER_EXCEL, index=False, engine='openpyxl')
            print(f"üéâ SUCCESS! Saved appended RS data to {RS_MASTER_CSV} and {RS_MASTER_EXCEL}")